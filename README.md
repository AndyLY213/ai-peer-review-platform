# AI Peer Review Platform

A comprehensive multi-agent simulation of the academic peer review process using AutoGen and Google Gemini AI.

## ğŸ¯ Overview

This platform simulates a realistic academic peer review ecosystem where AI-powered researchers:
- **Publish papers** in their areas of expertise
- **Review papers** from other researchers
- **Participate in a token-based economy** (spend tokens to request reviews, earn tokens by reviewing)
- **Exhibit realistic biases and behaviors** based on their specialties and career stages
- **Navigate complex academic dynamics** including funding, career progression, and institutional pressures

## âœ¨ Key Features

- **ğŸ¤– Multi-Agent System**: 10+ specialized researcher agents with distinct personalities and biases
- **ğŸ§  AI-Powered Reviews**: Realistic peer reviews generated using Google Gemini 2.0 Flash
- **ğŸ’° Token Economy**: Economic simulation of review requests and completions
- **ğŸ“Š Advanced Analytics**: Comprehensive metrics and performance tracking
- **ğŸ­ Bias Simulation**: Models real academic biases (confirmation bias, halo effect, etc.)
- **ğŸ›ï¸ Institutional Dynamics**: Career progression, funding systems, and venue prestige
- **ğŸ“ˆ Network Effects**: Citation networks, collaboration patterns, and academic communities
- **ğŸ”„ Reproducibility Tracking**: Research reproducibility and validation systems

## New Feature: PeerRead Dataset Integration

The simulation now supports loading real research papers from the [PeerRead dataset](https://github.com/allenai/PeerRead), a dataset of scientific papers and their reviews from various computer science conferences.

### Key Features

- Load real papers and reviews from the PeerRead dataset
- Process paper metadata (title, abstract, authors, etc.)
- Extract content from paper sections
- Link papers with their reviews
- Support for smaller test datasets for faster loading

## Directory Structure

```
PeerReview/
â”œâ”€â”€ config/                  # Configuration files
â”œâ”€â”€ src/                     # Source code
â”‚   â”œâ”€â”€ agents/              # Agent implementations
â”‚   â”œâ”€â”€ core/                # Core system components
â”‚   â”œâ”€â”€ data/                # Data management
â”‚   â”‚   â”œâ”€â”€ paper_database.py     # Paper database with PeerRead support
â”‚   â”‚   â”œâ”€â”€ create_test_dataset.py # Script to create test dataset
â”‚   â”‚   â”œâ”€â”€ test_paper_database.py # Test script for PaperDatabase
â”‚   â”‚   â””â”€â”€ token_system.py        # Token economy system
â”‚   â””â”€â”€ simulation/          # Simulation logic
â”‚       â””â”€â”€ peer_review_simulation.py # Main simulation system
â”œâ”€â”€ test_dataset/            # Smaller dataset for testing (generated)
â”œâ”€â”€ main.py                  # Entry point
â””â”€â”€ README.md                # This file
```

## ğŸš€ Quick Start

### Prerequisites

- **Python 3.8+** (recommended: Python 3.10+)
- **Google Gemini API Key** (get one at [Google AI Studio](https://makersuite.google.com/app/apikey))

### Installation

1. **Clone the repository**:
```bash
git clone https://github.com/yourusername/ai-peer-review-platform.git
cd ai-peer-review-platform
```

2. **Create and activate a virtual environment**:
```bash
python -m venv .venv

# On Windows
.venv\Scripts\activate

# On macOS/Linux
source .venv/bin/activate
```

3. **Install dependencies**:
```bash
pip install -r requirements.txt
```

4. **Configure environment**:
```bash
# Copy the example environment file
cp .env.example .env.local

# Edit .env.local and add your Gemini API key
# GEMINI_API_KEY=your_actual_api_key_here
```

5. **Run the simulation**:
```bash
python main.py
```

### Alternative Installation Methods

**Using pip (development install)**:
```bash
pip install -e .
```

**With optional dependencies**:
```bash
pip install -e ".[dev,viz,analysis]"
```

## ğŸ® Running Simulations

### Basic Usage

```bash
python main.py
```

The platform offers three simulation modes:

1. **ğŸ¤– Automated Mode**: Run multiple rounds of interactions automatically
2. **ğŸ’¬ Interactive Mode**: Chat directly with researcher agents
3. **ğŸ”„ Hybrid Mode**: Set up researchers then interact manually

### Example Simulation Output

```
ğŸ”¬ Peer Review Simulation System
--------------------------------
Simulation Modes:
1. Interactive Mode (chat with researchers)
2. Automated Simulation (run rounds of interactions)
3. Hybrid Mode (setup researchers and then interact)

Enter simulation mode (1-3): 2
Enter number of simulation rounds: 3
Enter number of interactions per round: 15

Creating researcher agents...
âœ“ Added AI_Researcher (Artificial Intelligence)
âœ“ Added NLP_Researcher (Natural Language Processing)
âœ“ Added CV_Researcher (Computer Vision)
...

Final Results:
- Total Reviews Completed: 42
- Total Tokens Exchanged: 1,250
- Top Performer: AI_Researcher (350 tokens)
```

### Testing the Paper Database

To test the PaperDatabase with the PeerRead integration:

```bash
python src/data/test_paper_database.py
```

This will:
1. Initialize a test database
2. Load papers from the test dataset
3. Print statistics about the loaded papers
4. Test basic functionality like searching and filtering

## Working with the PeerRead Dataset

### Manually Loading Papers

You can manually load papers from the PeerRead dataset:

```python
from src.data.paper_database import PaperDatabase

# Initialize database
db = PaperDatabase()

# Load from the test dataset
db.load_peerread_dataset(use_test_dataset=True)

# Or load from the full dataset with a limit
db.load_peerread_dataset(use_test_dataset=False, limit=100)

# Get paper statistics
papers = db.get_all_papers()
print(f"Loaded {len(papers)} papers")
```

### Creating a Custom Test Dataset

You can modify the `create_test_dataset.py` script to create a custom test dataset:

```python
# Configuration
SOURCE_DIR = "../../PeerRead/data"
TARGET_DIR = "../../PeerReview/test_dataset"
PAPERS_PER_CONFERENCE = 10  # Adjust number of papers per conference
INCLUDE_REVIEWS = True
```

## ğŸ—ï¸ Architecture

```
ai-peer-review-platform/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ agents/              # Researcher agents and templates
â”‚   â”œâ”€â”€ core/                # Core systems (tokens, LLM clients)
â”‚   â”œâ”€â”€ data/                # Data models and database
â”‚   â”œâ”€â”€ enhancements/        # Advanced features (bias, networks, etc.)
â”‚   â””â”€â”€ simulation/          # Main simulation engine
â”œâ”€â”€ tests/                   # Test suites
â”œâ”€â”€ peer_review_workspace/   # Generated simulation data
â”œâ”€â”€ .env.example            # Environment template
â”œâ”€â”€ requirements.txt        # Dependencies
â””â”€â”€ main.py                # Entry point
```

## ğŸ”§ Configuration

### Environment Variables

Key configuration options in `.env.local`:

```bash
# AI Provider
GEMINI_API_KEY=your_key_here
GEMINI_MODEL=gemini-2.0-flash
LLM_TEMPERATURE=0.7

# Simulation Settings
DEFAULT_RESEARCHERS=10
DEFAULT_TOKENS=100
ENABLE_BIAS_SIMULATION=true

# Performance
MAX_CONCURRENT_CALLS=5
REQUEST_TIMEOUT=30
```

### Researcher Personalities

Each researcher has unique characteristics:
- **AI_Researcher**: Prefers practical applications
- **Theory_Researcher**: Values mathematical rigor
- **Ethics_Researcher**: Emphasizes societal impact
- **Security_Researcher**: Focuses on threat models
- And 6 more specialized researchers...

## ğŸ§ª Testing

Run the test suite:
```bash
# Basic tests
python -m pytest tests/

# With coverage
python -m pytest tests/ --cov=src --cov-report=html

# Specific test
python test_simple.py
```

## ğŸ¤ Contributing

We welcome contributions! Please see our contributing guidelines:

1. **Fork the repository**
2. **Create a feature branch**: `git checkout -b feature/amazing-feature`
3. **Make your changes** and add tests
4. **Run tests**: `pytest tests/`
5. **Submit a pull request**

### Development Setup

```bash
# Install with development dependencies
pip install -e ".[dev]"

# Run code formatting
black src/ tests/

# Run linting
flake8 src/ tests/

# Run type checking
mypy src/
```

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- **AutoGen/AG2** for the multi-agent framework
- **Google Gemini** for AI-powered review generation
- **PeerRead Dataset** for real academic paper data
- The academic community for inspiration and validation

## ğŸ“ Support

- **Issues**: [GitHub Issues](https://github.com/yourusername/ai-peer-review-platform/issues)
- **Discussions**: [GitHub Discussions](https://github.com/yourusername/ai-peer-review-platform/discussions)
- **Email**: contact@example.com

---

**â­ Star this repository if you find it useful!** 